{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "\n",
    "def extract_links(data):\n",
    "    extractor = URLExtract()\n",
    "    links = []\n",
    "    for message in data:\n",
    "        links.extend(extractor.find_urls(message))\n",
    "    x=''\n",
    "    for i in data.split():\n",
    "      if i not in links :\n",
    "        x=x+i+' '\n",
    "    return links\n",
    "        \n",
    "def stemming_stop(content):\n",
    "    port_stem = PorterStemmer()\n",
    "    stemmed_content = content\n",
    "    stemmed_content = stemmed_content.lower() \n",
    "    stemmed_content = stemmed_content.split() \n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] \n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content\n",
    "    \n",
    "\n",
    "def clean(data):\n",
    "    cleaned_data = data\n",
    "    cleaned_data = re.sub(r'\\S*@\\S*\\s?', '', cleaned_data)\n",
    "    cleaned_data = re.sub(r'[^\\w\\s.,]', '', cleaned_data)\n",
    "    cleaned_data = re.sub(r'[0-9]', '', cleaned_data)\n",
    "    return cleaned_data\n",
    "\n",
    "def remove_underscores(data):\n",
    "    new_string = \"\"\n",
    "    for x in data:\n",
    "        if (x=='_'):\n",
    "            new_string += ''\n",
    "        else:\n",
    "            new_string+=x\n",
    "    return new_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pke_model(model , data):\n",
    "  model.load_document(input=data , language=\"en\")       \n",
    "  model.candidate_selection()           \n",
    "  model.candidate_weighting()             \n",
    "  keyphrases = model.get_n_best(n=20)\n",
    "  return keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "def for_function(model):\n",
    "  for i in model:\n",
    "    y.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from flashtext import KeywordProcessor\n",
    "\n",
    "def tokenize_sentences(text):\n",
    "    sentences = [sent_tokenize(text)]\n",
    "    sentences = [y for x in sentences for y in x]\n",
    "    # Remove any short sentences less than 20 letters.\n",
    "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
    "    return sentences\n",
    "\n",
    "def get_sentences_for_keyword(keywords, sentences):\n",
    "    keyword_processor = KeywordProcessor()\n",
    "    keyword_sentences = {}\n",
    "    for word in keywords:\n",
    "        keyword_sentences[word] = []\n",
    "        keyword_processor.add_keyword(word)\n",
    "    for sentence in sentences:\n",
    "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
    "        for key in keywords_found:\n",
    "            keyword_sentences[key].append(sentence)\n",
    "\n",
    "    for key in keyword_sentences.keys():\n",
    "        values = keyword_sentences[key]\n",
    "        values = sorted(values, key=len, reverse=True)\n",
    "        keyword_sentences[key] = values\n",
    "    return keyword_sentences\n",
    "\n",
    "sentences = tokenize_sentences(our_data)\n",
    "keyword_sentence_mapping = get_sentences_for_keyword(y, sentences)\n",
    "        \n",
    "print (keyword_sentence_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_KP(keyphrases):\n",
    "  common_KP = {\n",
    "    \n",
    "  }\n",
    "  for i, (candidate, score) in enumerate(keyphrases):\n",
    "    \n",
    "      if common_KP.get(candidate) != None:\n",
    "          common_KP[candidate] = common_KP[candidate] = common_KP[candidate]+1\n",
    "      else:\n",
    "         common_KP[candidate] = 1\n",
    "  return common_KP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parargraph_function(keyword_sentence_mapping):\n",
    "  paragraphs = []\n",
    "  for x in keyword_sentence_mapping:\n",
    "    try:\n",
    "      paragraphs.append(keyword_sentence_mapping[x][0])\n",
    "    except:\n",
    "      pass\n",
    "  return paragraphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
